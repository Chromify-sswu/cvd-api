# server.py
import io
import base64
from typing import List

from fastapi import FastAPI, HTTPException
from fastapi.middleware.cors import CORSMiddleware
from pydantic import BaseModel
from PIL import Image, ImageOps

import torch
import torch.nn.functional as F
import torchvision.transforms as T

from film_unet import FiLM_UNet

DEVICE = "cuda" if torch.cuda.is_available() else "cpu"
MODEL_PATH = "film_unet_best.pth"

# ---- ëª¨ë¸ ë¡œë“œ (ì„œë²„ ì‹œì‘ ì‹œ 1ë²ˆë§Œ) ----
model = FiLM_UNet(user_dim=4)
state = torch.load(MODEL_PATH, map_location=DEVICE)
model.load_state_dict(state)
model.to(DEVICE)
model.eval()

img_transform = T.Compose([
    T.Resize(256),
    T.CenterCrop((256, 256)),
    T.ToTensor(),  # (C,H,W) 0~1
])


class CorrectionRequest(BaseModel):
    image: str          # base64 ë¬¸ìì—´
    user_vec: List[float]   # [p, d, t, deltaE]


app = FastAPI()

# ---- CORS (ì•±/ì›¹ì—ì„œ í˜¸ì¶œí•˜ê¸° ì‰½ê²Œ) ----
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],      # ê°œë°œ ë‹¨ê³„: ì „ì²´ í—ˆìš©
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

@app.get("/ping")
def ping():
    return {"message": "pong"}


@app.post("/correct")
def correct_color(req: CorrectionRequest):
    if len(req.user_vec) != 4:
        raise HTTPException(
            status_code=400,
            detail=f"user_vec must be length 4, got {len(req.user_vec)}",
        )

    # 1) base64 â†’ PIL (íšŒì „ ë³´ì • í¬í•¨)
    img_bytes = base64.b64decode(req.image)
    pil_img = Image.open(io.BytesIO(img_bytes))
    pil_img = ImageOps.exif_transpose(pil_img).convert("RGB")

    # 2) ì „ì²˜ë¦¬
    x = img_transform(pil_img).unsqueeze(0).to(DEVICE)  # (1,3,256,256)

    user_vec = torch.tensor(
        [req.user_vec], dtype=torch.float32, device=DEVICE
    )  # (1,4)

    with torch.no_grad():
        # 3) ëª¨ë¸ ì¶”ë¡ 
        y = model(x, user_vec)   # (1,3,256,256), 0~1

        # ğŸ”§ ê³ ì£¼íŒŒ ë…¸ì´ì¦ˆ ì¤„ì´ê¸°
        y = F.avg_pool2d(y, kernel_size=3, stride=1, padding=1)

        # ğŸ”§ ì›ë³¸ê³¼ ë¸”ë Œë”©í•´ì„œ ëœ ê¹¨ì ¸ ë³´ì´ê²Œ
        alpha = 0.6  # 0.0 = ì›ë³¸ / 1.0 = ëª¨ë¸ ê·¸ ìì²´
        y = alpha * y + (1.0 - alpha) * x

    y = y.squeeze(0).cpu().clamp(0, 1)

    out_pil = T.ToPILImage()(y)

    buf = io.BytesIO()
    out_pil.save(buf, format="PNG")
    out_b64 = base64.b64encode(buf.getvalue()).decode("utf-8")

    return {"corrected_image": out_b64}


# ë¡œì»¬ í…ŒìŠ¤íŠ¸ìš© (Renderì—ì„œëŠ” ì•ˆ ì¨ë„ ë¨)
if __name__ == "__main__":
    import uvicorn
    uvicorn.run("server:app", host="0.0.0.0", port=8000, reload=True)
